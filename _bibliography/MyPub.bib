@inproceedings{egeleAutodeuqAutomatedDeep2022,
  title = {Autodeuq: {{Automated}} Deep Ensemble with Uncertainty Quantification},
  shorttitle = {Autodeuq},
  booktitle = {26th {{International Conference}} on {{Pattern Recognition}} ({{ICPR}})},
  author = {Egele, Romain and Maulik, Romit and Raghavan, Krishnan and Lusch, Bethany and Guyon, Isabelle and Balaprakash, Prasanna},
  year = {2022},
  pages = {1908--1914},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/9956231},
  bibtex_show={true},
}

@inproceedings{gargDistributedLearningDeep2018a,
  title = {Distributed Learning of Deep Sparse Neural Networks for High-Dimensional Classification},
  booktitle = {{{IEEE International Conference}} on {{Big Data}} ({{AR}}:18.7)},
  author = {Garg, Shweta and Raghavan, Krishnan and Jagannathan, Sarangapani and Samaranayake, V. A.},
  year = {2018},
  pages = {1587--1592},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/8621888},
  bibtex_show={true},
}

@inproceedings{gargSFSFDStochasticOptimization2023,
  title = {{{SF-SFD}}: {{Stochastic Optimization}} of {{Fourier Coefficients}} to {{Generate Space-Filling Designs}}},
  booktitle = {Winter {{Simulation Conference}}, Accepted},
  author = {Garg, Manisha and Chang, Tyler and Raghavan, Krishnan},
  year = {2023},
  url = {https://arxiv.org/abs/4905322},
  bibtex_show={true}
}

@article{jinGraphNeuralNetworks2023,
  title = {‪{{Graph Neural Networks}} for {{Detecting Anomalies}} in {{Scientific Workflows}}},
  author = {Jin, Hongwei and Raghavan, Krishnan and Papadimitriou, George and Wang, Cong and Anirban, Mandal and Mariam, Kiran and Ewa, Deelman and Balaprakash, Prasanna},
  year = {2023},
  journaltitle = {International Journal of high performance computing applications (IF:2.457)},
  url = {https://journals.sagepub.com/doi/abs/10.1177/10943420231172140?journalCode=hpcc},
  bibtex_show={true}
}

@inproceedings{jinWorkflowAnomalyDetection2022,
  title = {Workflow {{Anomaly Detection}} with {{Graph Neural Networks}}},
  booktitle = {{{IEEE-ACM Workshop}} on {{Workflows}} in {{Support}} of {{Large-Scale Science}} ({{WORKS}})},
  author = {Jin, Hongwei and Raghavan, Krishnan and Papadimitriou, George and Wang, Cong and Mandal, Anirban and Krawczuk, Patrycja and Pottier, Loïc and Kiran, Mariam and Deelman, Ewa and Balaprakash, Prasanna},
  year = {2022-11},
  pages = {35--42},
  doi = {10.1109/WORKS56498.2022.00010},
  abstract = {Reliable execution of scientific workflows is a fundamental concern in computational campaigns. Therefore, detecting and diagnosing anomalies are both important and challenging for workflow executions that span complex, distributed computing infrastructures. In this paper we model the scientific workflow as a directed acyclic graph and apply graph neural networks (GNNs) to identify the anomalies at both the workflow and individual job levels. In addition, we generalize our GNN model to take into account a set of workflows together for the anomaly detection task rather than a specific workflow. By taking advantage of learning the hidden representation, not only from the job features, but also from the topological information of the workflow, our GNN models demonstrate higher accuracy and better runtime efficiency when compared with conventional machine learning models and other convolutional neural network approaches.},
  keywords = {Anomaly detection,Computational modeling,Convolutional neural networks,Directed acyclic graph,Graph neural networks,Machine learning,Reliability,Runtime,Scientific workflows},
  file = {/Users/krishnanraghavan/Zotero/storage/Z6IAN2BI/Jin et al_2022_Workflow Anomaly Detection with Graph Neural Networks.pdf;/Users/krishnanraghavan/Zotero/storage/7V78PQZZ/10023943.html},
  bibtex_show={true},
}

@inproceedings{KRISHNAN201881,
  title = {A Multi-Step Nonlinear Dimension-Reduction Approach with Applications to Bigdata},
  booktitle = {{{INNS}} Conference on {{Big Data}} and {{Deep Learning}}},
  author = {Raghavan, Krishnan and Samaranayake, V.A. and Jagannathan, S.},
  year = {2018},
  volume = {144},
  pages = {81--88},
  doi = {10.1016/j.procs.2018.10.507},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050918322166},
  abstract = {In this paper, a multi-step dimension-reduction approach is proposed for addressing nonlinear relationships within attributes. In this work, the attributes in the data are first organized into groups. In each group, the dimensions are reduced via a parametric mapping that takes into account nonlinear relationships. Mapping parameters are estimated using a low rank singular value decomposition (SVD) of distance covariance. Subsequently, the attributes are reorganized into groups based on the magnitude of their respective singular values. The group-wise organization and the subsequent reduction process is performed for multiple steps until a singular value-based user-defined criterion is satisfied. Simulation analysis is utilized to investigate the performance with five big data-sets.},
  bibtex_show={true}
}

@online{maulikQuantifyingUncertaintyDeep,
  title = {Quantifying Uncertainty for Deep Learning Based Forecasting and Flow-Reconstruction Using Neural Architecture Search Ensembles},
  author = {Maulik, Romit and Egele, Romain and Raghavan, Krishnan and Balaprakash, Prasanna},
  doi = {Physica D: Nonlinear Phenomena},
  url = {http://arxiv.org/abs/2302.09748},
  abstract = {Classical problems in computational physics such as data-driven forecasting and signal reconstruction from sparse sensors have recently seen an explosion in deep neural network (DNN) based algorithmic approaches. However, most DNN models do not provide uncertainty estimates, which are crucial for establishing the trustworthiness of these techniques in downstream decision making tasks and scenarios. In recent years, ensemble-based methods have achieved significant success for the uncertainty quantification in DNNs on a number of benchmark problems. However, their performance on real-world applications remains under-explored. In this work, we present an automated approach to DNN discovery and demonstrate how this may also be utilized for ensemble-based uncertainty quantification. Specifically, we propose the use of a scalable neural and hyperparameter architecture search for discovering an ensemble of DNN models for complex dynamical systems. We highlight how the proposed method not only discovers high-performing neural network ensembles for our tasks, but also quantifies uncertainty seamlessly. This is achieved by using genetic algorithms and Bayesian optimization for sampling the search space of neural network architectures and hyperparameters. Subsequently, a model selection approach is used to identify candidate models for an ensemble set construction. Afterwards, a variance decomposition approach is used to estimate the uncertainty of the predictions from the ensemble. We demonstrate the feasibility of this framework for two tasks - forecasting from historical data and flow reconstruction from sparse sensors for the sea-surface temperature. We demonstrate superior performance from the ensemble in contrast with individual high-performing models and other benchmarks.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Mathematics - Dynamical Systems},
  file = {/Users/krishnanraghavan/Zotero/storage/W4IRR2BN/Maulik et al_2023_Quantifying uncertainty for deep learning based forecasting and.pdf;/Users/krishnanraghavan/Zotero/storage/K7HXV3N9/2302.html},
  bibtex_show={true}
}

@incollection{moghadamOptimalAdaptiveControl2021,
  title = {Optimal {{Adaptive Control}} of {{Partially Uncertain Linear Continuous-Time Systems}} with {{State Delay}}},
  booktitle = {Handbook of {{Reinforcement Learning}} and {{Control}}},
  author = {Moghadam, Rohollah and Jagannathan, S. and Narayanan, Vignesh and Raghavan, Krishnan},
  year = {2021},
  publisher = {{Springer}},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-60990-0_9},
  bibtex_show={true}
}

@article{raghavanClassificationEventsBackslashalpha2023,
  title = {Classification of Events from \$\textbackslash backslashalpha \$-Induced Reactions in the {{MUSIC}} Detector via Statistical and {{ML}} Methods},
  author = {Raghavan, Krishnan and Avila, Melina L. and Balaprakash, Prasanna and Jayatissa, Heshani and Santiago-Gonzalez, Daniel},
  year = {2023},
  journaltitle = {Nuclear Inst. and Methods in Physics Research, A  (IF: 1.335), Accepted},
  url = {https://arxiv.org/pdf/2204.03137.pdf},
  bibtex_show={true}
}

@thesis{raghavanComputerVisionLibraries2014,
  title = {Computer Vision Libraries for Trailer Truck Testbed Using Open Source Computer Vision Libraries},
  author = {Raghavan, Krishnan},
  year = {2014},
  institution = {{Missouri University of Science and Technology}}
}

@inproceedings{raghavanContinualLearningDynamic2022,
  title = {Continual Learning via Dynamic Programming},
  booktitle = {International {{Conference}} on {{Pattern Recognition}}},
  author = {Raghavan, Krishnan and Balaprakash, Prasanna},
  year = {2022},
  url = {https://ieeexplore.ieee.org/document/9956042},
  bibtex_show={true},
  selected={true}
}

@article{raghavanCooperativeDeepLearning2023,
  title = {Cooperative {{Deep Q}} -{{Learning Framework}} for {{Environments Providing Image Feedback}}},
  author = {Raghavan, Krishnan and Narayanan, Vignesh and Jagannathan, Sarangapani},
  year = {2023},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems (IF:11.683), Accepted},
  volume = {0},
  number = {0},
  pages = {0},
  publisher = {{IEEE}},
  doi = {Accepted for Publicatioin},
  url = {https://ieeexplore.ieee.org/abstract/document/10012540},
  bibtex_show={true}
}

@inproceedings{raghavanDeepLearningInspired2017,
  title = {Deep Learning Inspired Prognostics Scheme for Applications Generating Big Data},
  booktitle = {International {{Joint Conference}} on {{Neural Networks}} ({{AR}}:15)},
  author = {Raghavan, Krishnan and Jagannathan, Sarangapani and Samaranayake, V. A.},
  year = {2017},
  pages = {3296--3302},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/7966269},
  bibtex_show={true}
}

@thesis{raghavanDeepNeuralNetwork2019,
  title = {Deep Neural Network Learning-Based Classifier Design for Big-Data Analytics},
  author = {Raghavan, Krishnan},
  year = {2019},
  institution = {{Missouri University of Science and Technology}},
  bibtex_show={true}
}

@inproceedings{raghavanDirectErrorDriven2018,
  title = {Direct Error Driven Learning for Deep Neural Networks with Applications to Bigdata},
  booktitle = {International {{Conference}} on {{Big Data}} and {{Deep Learning}}},
  author = {Raghavan, Krishnan and Jagannathan, Sarangapani and Samaranayake, V. A.},
  year = {2018},
  volume = {144},
  pages = {89--95},
  publisher = {{Elsevier}},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-31764-5_1https://link.springer.com/chapter/10.1007/978-3-030-31764-5_1},
  bibtex_show={true}
}

@incollection{raghavanDirectErrorDriven2020,
  title = {Direct {{Error Driven Learning}} for {{Classification}} in {{Applications Generating Big-Data}}},
  booktitle = {Development and {{Analysis}} of {{Deep Learning Architectures}}},
  author = {Raghavan, Krishnan and Jagannathan, S. and Samaranayake, V. A.},
  year = {2020},
  pages = {1--29},
  publisher = {{Springer}},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050918322178},
  bibtex_show={true}
}

@article{raghavanDirectErrordrivenLearning2019,
  title = {Direct Error-Driven Learning for Deep Neural Networks with Applications to Big Data},
  author = {Raghavan, Krishnan and Jagannathan, Sarangapani and Samaranayake, V. A.},
  year = {2019},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems (IF:11.623)},
  volume = {31},
  number = {5},
  pages = {1763--1770},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/8763927},
  bibtex_show={true}
}

@article{raghavanDistributedMinMax2020,
  title = {Distributed {{Min}}–{{Max Learning Scheme}} for {{Neural Networks With Applications}} to {{High-Dimensional Classification}}},
  author = {Raghavan, Krishnan and Garg, Shweta and Jagannathan, Sarangapani and Samaranayake, V. A.},
  year = {2020},
  journaltitle = {IEEE transactions on neural networks and learning systems (IF:11.623)},
  volume = {32},
  number = {10},
  pages = {4323--4333},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/9199282},
  bibtex_show={true}
}

@inproceedings{raghavanFormalizingGeneralizationforgettingTradeoff2021,
  title = {Formalizing the Generalization-Forgetting Trade-off in Continual Learning},
  booktitle = {Advances in {{Neural Information Processing Systems}} ({{AR}}:20)},
  author = {Raghavan, Krishnan and Balaprakash, Prasanna},
  year = {2021},
  volume = {34},
  pages = {17284--17297},
  url = {https://proceedings.neurips.cc/paper/2021/hash/901797aebf0b23ecbab534d61ad33bb1-Abstract.html},
  bibtex_show={true},
  selected={true}
}

@article{raghavanGameTheoreticApproach2021,
  title = {A {{Game Theoretic Approach}} for {{Addressing Domain-Shift}} in {{Big-Data}}},
  author = {Raghavan, Krishnan and Jagannathan, Sarangapani and Samaranayake, V. A.},
  year = {2021},
  journaltitle = {IEEE Transactions on Big Data (IF: 4.27)},
  volume = {8},
  number = {6},
  pages = {1610--1621},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/9424459},
  bibtex_show={true}
}

@article{raghavanHierarchicalDimensionReduction2019,
  title = {A Hierarchical Dimension Reduction Approach for Big Data with Application to Fault Diagnostics},
  author = {Raghavan, Krishnan and Samaranayake, V. A. and Jagannathan, S.},
  year = {2019},
  journaltitle = {Big Data Research (IF: 3.739)},
  volume = {18},
  number = {0},
  pages = {100121},
  publisher = {{Elsevier}},
  url = {https://www.sciencedirect.com/science/article/pii/S2214579619302102},
  bibtex_show={true}
}

@inproceedings{raghavanHierarchicalMahalanobisDistance2015,
  title = {Hierarchical {{Mahalanobis Distance Clustering Based Technique}} for {{Prognostics}} in {{Applications Generating Big Data}}},
  booktitle = {{{IEEE Symposium Series}} on {{Computational Intelligence}}},
  author = {Raghavan, Krishnan and Jagannathan, Sarangapani},
  year = {2015},
  pages = {516--521},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/7376655},
  bibtex_show={true}
}

@online{raghavanLearningContinuallySequence2023,
  title = {Learning {{Continually}} on a {{Sequence}} of {{Graph}} -- {{The Dynamical System Way}}},
  author = {Raghavan, Krishnan and Balaprakash, Prasanna},
  year = {2023},
  doi = {SIAM Journal on Mathematics of Data Science},
  url = {https://arxiv.org/abs/2305.12030},
  pubstate = {preprint},
  selected={true},
  bibtex_show={true}
}

@online{raghavanLearningControlUsing2023,
  title = {Learning to {{Control}} Using {{Image Feedback}}},
  author = {Raghavan, Krishnan and Narayanan, Vignesh and Saraangapani, Jagannathan},
  year = {2023},
  url = {https://arxiv.org/abs/2110.15290},
  pubstate = {preprint},
  bibtex_show={true}
}

@article{raghavanMachinelearningbasedInversionNuclear2021,
  title = {Machine-Learning-Based Inversion of Nuclear Responses},
  author = {Raghavan, Krishnan and Balaprakash, Prasanna and Lovato, Alessandro and Rocco, Noemi and Wild, Stefan M.},
  year = {2021},
  journaltitle = {Physical Review C (IF: 3.09)},
  volume = {103},
  number = {3},
  pages = {035502},
  publisher = {{APS}},
  url = {https://journals.aps.org/prc/abstract/10.1103/PhysRevC.103.035502},
  bibtex_show={true}
}

@inproceedings{raghavanMinimaxApproachClassification2018,
  title = {A {{Minimax Approach}} for {{Classification}} with {{Big-data}}},
  booktitle = {{{IEEE International Conference}} on {{Big Data}} ({{AR}}: 18.7)},
  author = {Raghavan, Krishnan and Jagannathan, Sarangapani and Samaranayake, V. A.},
  year = {2018},
  pages = {1437--1444},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/8622564},
  bibtex_show={true}
}

@article{raghavanMultistepNonlinearDimensionreduction2018,
  title = {A Multi-Step Nonlinear Dimension-Reduction Approach with Applications to Big Data},
  author = {Raghavan, Krishnan and Samaranayake, V. A. and Jagannathan, Sarangapani},
  year = {2018},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering (IF: 9.235)},
  volume = {31},
  number = {12},
  pages = {2249--2261},
  publisher = {{IEEE}},
  url = {https://ieeexplore.ieee.org/abstract/document/8496836}
}

@incollection{sunIntroductionReinforcementLearning,
  title = {Introduction to {{Reinforcement Learning}}},
  booktitle = {Autonomous {{Experimentation}} Book, Accepted},
  author = {Sun, Yixuan and Raghavan, Krishnan and Balaprakash, Prasanna},
  publisher = {{Taylor \& Francis}},
  annotation = {review}
}

@inproceedings{yildizAutomatedContinualLearning2022,
  title = {Automated {{Continual Learning}} of {{Defect Identification}} in {{Coherent Diffraction Imaging}}},
  booktitle = {{{IEEE}}/{{ACM International Workshop}} on {{Artificial Intelligence}} and {{Machine Learning}} for {{Scientific Applications}} ({{AI4S}})},
  author = {Yildiz, Orcun and Chan, Henry and Raghavan, Krishnan and Judge, William and Cherukara, Mathew J. and Balaprakash, Prasanna and Sankaranarayanan, Subramanian and Peterka, Tom},
  year = {2022},
  pages = {1--6},
  url = {https://ieeexplore.ieee.org/document/10027574},
  abstract = {X-ray Bragg coherent diffraction imaging (BCDI) is widely used for materials characterization. However, obtaining X-ray diffraction data is difficult and computationally intensive. Here, we introduce a machine learning approach to identify crystalline line defects in samples from the raw coherent diffraction data. To automate this process, we compose a workflow coupling coherent diffraction data generation with training and inference of deep neural network defect classifiers. In particular, we adopt a continual learning approach, where we generate training and inference data as needed based on the accuracy of the defect classifier instead of all training data generated a priori. The results show that our approach improves the accuracy of defect classifiers while using much fewer samples of data.},
  keywords = {catastrophic forgetting,continual learning,Deep learning,defect identification,Diffraction,HPC workflows,Imaging,Neural networks,Three-dimensional displays,Training,Training data},
  file = {/Users/krishnanraghavan/Zotero/storage/T49JX2MN/10027574.html},
   selected={true}
}
